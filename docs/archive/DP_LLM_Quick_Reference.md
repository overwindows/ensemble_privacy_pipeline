# Differential Privacy for LLMs - Quick Reference

## ğŸ¯ Core Findings (TL;DR)

1. **DP at inference for text generation = BAD** âŒ
   - Unreadable output even with weak privacy (Îµ=15)
   - High dimensionality + sequential generation = fundamental failure
   
2. **DP-SGD (training time) = GOOD** âœ…
   - Add DP during training, normal inference
   - Perfect text quality, strong privacy guarantees
   
3. **DP embeddings = GOOD** âœ…  
   - Works great for search/clustering
   - Lower dimensionality (768 vs 50k)

4. **Query clustering is CRITICAL** âš ï¸
   - Can only aggregate similar queries
   - Diverse queries â†’ gibberish output

---

## ğŸ“Š Quick Comparison Table

| Approach | Privacy | Quality | When to Use |
|----------|---------|---------|-------------|
| DP-SGD | âœ… Strong | âœ… Perfect | Fine-tuning LLMs |
| DP Embeddings | âœ… Good | âœ… Good | Search/clustering |
| DP at Inference | âŒ Weak | âŒ Poor | Don't use (educational only) |

---

## ğŸ”‘ Key Equations

**Gaussian Mechanism**:
```
Ïƒ = sensitivity Ã— âˆš(2 Ã— ln(1.25/Î´)) / Îµ
noisy_output = true_output + N(0, ÏƒÂ²)
```

**Privacy-Utility Trade-off**:
- Îµ < 1: Very private, unusable quality
- Îµ = 1-3: Private, poor quality  
- Îµ = 5-10: Moderate privacy, marginal quality
- Îµ > 15: Weak privacy, acceptable quality

---

## ğŸ’¡ Practical Recommendations

**Scenario: Users with sensitive queries**

### Option 1: DP-SGD (BEST) â­
```python
from opacus import PrivacyEngine

# 1. Collect private queries
# 2. Fine-tune with DP-SGD
privacy_engine = PrivacyEngine()
model, optimizer, loader = privacy_engine.make_private(
    module=model, optimizer=optimizer, data_loader=loader,
    noise_multiplier=1.1, max_grad_norm=1.0
)

# 3. Train normally
# 4. Deploy - inference is normal!
```

### Option 2: DP Embeddings (for search)
```python
# 1. Get embeddings
embeddings = model.encode(queries)

# 2. Add DP noise
Ïƒ = 2 * np.sqrt(2 * np.log(1.25/1e-5)) / epsilon
private_emb = embeddings + np.random.normal(0, Ïƒ, embeddings.shape)

# 3. Use for search/clustering
```

### Option 3: DP at Inference (AVOID)
- Only works with Îµ > 15 (weak privacy)
- Requires similar queries (clustering challenge)
- Poor quality, not production-ready

---

## ğŸš« Common Pitfalls

1. **Using DP at inference for generation** - Won't work well
2. **Aggregating diverse queries** - Produces gibberish
3. **Top-k too large (100+)** - Noise affects too many dimensions
4. **Epsilon too low (<10)** - Text is unreadable
5. **Not clustering first** - Mixed queries = bad output

---

## âœ… Success Criteria

**For DP-SGD**:
- Epsilon: 1-10
- Delta: 10â»âµ
- Model accuracy drop: <5%
- Inference: Normal speed

**For DP Embeddings**:
- Epsilon: 0.5-2
- Delta: 10â»âµ  
- Cosine similarity preserved: >0.8
- Clustering quality: >80% of original

---

## ğŸ“š Essential Resources

- **Opacus**: https://opacus.ai/
- **OpenDP**: https://docs.opendp.org/
- **Paper**: "Deep Learning with Differential Privacy" (Abadi et al., 2016)
- **Tutorial**: Google DP Blog

---

## ğŸ“ What We Discovered

### The Journey:
1. Started with DP at inference (standard approach)
2. Got gibberish output (unicode/multilingual garbage)
3. Fixed sampling (smaller top-k, higher Îµ, lower temp)
4. Still poor quality - discovered fundamental limitations
5. Realized similar queries needed - clustering challenge
6. Learned DP-SGD is the real solution

### The Lessons:
- High-dimensional + sequential = DP doesn't work
- Privacy-utility trade-off is harsh for text
- Add privacy during training, not inference
- Embeddings work better than generation

---

## ğŸ”§ Fixed Sampling Function (if you must try)

```python
def sample_token_FIXED(dp_logits, temperature=0.4, top_k=15, top_p=0.85):
    """Much better than original - but still limited."""
    logits = torch.tensor(dp_logits) / temperature
    
    # Very aggressive top-k (15, not 100!)
    top_k_logits, top_k_indices = torch.topk(logits, top_k)
    filtered = torch.full_like(logits, float('-inf'))
    filtered[top_k_indices] = top_k_logits
    
    # Top-p filtering
    sorted_logits, sorted_indices = torch.sort(filtered, descending=True)
    cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, -1), -1)
    remove = cumulative_probs > top_p
    remove[0] = False
    filtered[sorted_indices[remove]] = float('-inf')
    
    # Sample
    probs = torch.softmax(filtered, -1)
    return torch.multinomial(probs, 1).item()

# Use with Îµ â‰¥ 15 for any hope of readability
```

---

## ğŸ“ˆ Privacy Budget Guidelines

| Use Case | Recommended Îµ | Recommended Î´ | Notes |
|----------|---------------|---------------|-------|
| Medical records | 0.5-1.0 | 10â»â¶ | Very sensitive |
| Financial data | 1.0-3.0 | 10â»âµ | Sensitive |
| User queries | 3.0-10.0 | 10â»âµ | Moderately sensitive |
| Public data | >10.0 | 10â»âµ | Less sensitive |

**Note**: For text generation at inference, need Îµ > 15 for readability (weak privacy!)

---

## ğŸ¯ Decision Tree

```
Need to use LLM with private data?
â”‚
â”œâ”€ Fine-tuning on private data?
â”‚  â””â”€> Use DP-SGD âœ…
â”‚
â”œâ”€ Search/clustering only?
â”‚  â””â”€> Use DP Embeddings âœ…
â”‚
â”œâ”€ Text generation from aggregated queries?
â”‚  â”œâ”€ Queries similar?
â”‚  â”‚  â”œâ”€ Can accept Îµ > 15?
â”‚  â”‚  â”‚  â””â”€> Try DP at inference âš ï¸
â”‚  â”‚  â””â”€> No â†’ Use DP-SGD on training data âœ…
â”‚  â””â”€ Queries diverse?
â”‚     â””â”€> Cluster first, then decide âš ï¸
â”‚
â””â”€ Just using API (GPT-4, etc)?
   â””â”€> Can't add DP yourself (provider's responsibility)
```

---

## ğŸ† Bottom Line

**The Answer**: **Use DP-SGD for training, not DP at inference!**

- âœ… Privacy: Strong (Îµ = 1-10)
- âœ… Quality: Perfect (no noise at inference)
- âœ… Speed: Normal inference speed
- âœ… Production-ready: Used by major companies

**Don't fight the fundamental limits of DP text generation at inference time!**

